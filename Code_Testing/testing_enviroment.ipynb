{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Append the directory of clean_cresci_2015.py to sys.path\n",
    "sys.path.append(os.path.abspath(\"../Code\"))\n",
    "\n",
    "# Main libraries\n",
    "from import_data import ImportData\n",
    "from evaluation import Evaluate \n",
    "from feature_selection import FeatureSelection\n",
    "from models_test import ModelTester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parametres is the default value of each model, parametres can be optimized before a prediction using Cross Validation  \n",
    "Otherwise the parametres can be modified here and tested on each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_parametres = {\n",
    "    'decision_tree': {\n",
    "        'ccp_alpha': 0.0,\n",
    "        'class_weight': None,\n",
    "        'criterion': 'entropy',\n",
    "        'max_depth': 20,\n",
    "        'max_features': None,\n",
    "        'max_leaf_nodes': None,\n",
    "        'min_impurity_decrease': 0.0,\n",
    "        'min_samples_leaf': 1,\n",
    "        'min_samples_split': 10,\n",
    "        'min_weight_fraction_leaf': 0.0,\n",
    "        'random_state': None,\n",
    "        'splitter': 'random'\n",
    "        },\n",
    "\n",
    "    'knn': {\n",
    "        'algorithm': 'auto',\n",
    "        'leaf_size': 10,\n",
    "        'metric': 'minkowski',\n",
    "        'metric_params': None,\n",
    "        'n_jobs': None,\n",
    "        'n_neighbors': 3,\n",
    "        'p': 1,\n",
    "        'weights': 'uniform'\n",
    "        },\n",
    "\n",
    "    'logistic_regression': {\n",
    "        'C': 0.001,\n",
    "        'class_weight': None,\n",
    "        'dual': False,\n",
    "        'fit_intercept': True,\n",
    "        'intercept_scaling': 1,\n",
    "        'l1_ratio': None,\n",
    "        'max_iter': 50,\n",
    "        'multi_class': 'auto',\n",
    "        'n_jobs': None,\n",
    "        'penalty': 'l2',\n",
    "        'random_state': None,\n",
    "        'solver': 'newton-cg',\n",
    "        'tol': 0.0001,\n",
    "        'verbose': 0,\n",
    "        'warm_start': False\n",
    "        },\n",
    "\n",
    " 'svm': {\n",
    "    'C': 1000,\n",
    "    'break_ties': False,\n",
    "    'cache_size': 200,\n",
    "    'class_weight': 'balanced',\n",
    "    'coef0': 0.1,\n",
    "    'decision_function_shape': 'ovr',\n",
    "    'degree': 2,\n",
    "    'gamma': 'scale',\n",
    "    'kernel': 'poly',\n",
    "    'max_iter': -1,\n",
    "    'probability': True,\n",
    "    'random_state': None,\n",
    "    'shrinking': True,\n",
    "    'tol': 0.001,\n",
    "    'verbose': False\n",
    "  }\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_results(\n",
    "    model_parametres,\n",
    "    test_metrics,\n",
    "    val_metrics,\n",
    "    DATASET,\n",
    "    BOT_FOLDERS,\n",
    "    BOT_RATIO,\n",
    "    MERGED_DATASET,\n",
    "    TYPE_SELECTION,\n",
    "    TRAIN_RATE,\n",
    "    TEST_RATE,\n",
    "    VAL_RATE,\n",
    "    MODEL,\n",
    "    FEATURES\n",
    "):\n",
    "    # Expand the dictionaries with appropriate prefixes\n",
    "    data = {\n",
    "        \"DATASET\": DATASET,\n",
    "        \"BOT_FOLDERS\": str(BOT_FOLDERS),\n",
    "        \"BOT_RATIO\": str(BOT_RATIO),\n",
    "        \"MERGED_DATASET\": MERGED_DATASET,\n",
    "        \"TYPE_SELECTION\": TYPE_SELECTION,\n",
    "        \"TRAIN_RATE\": TRAIN_RATE,\n",
    "        \"TEST_RATE\": TEST_RATE,\n",
    "        \"VAL_RATE\": VAL_RATE,\n",
    "        \"MODEL\": MODEL,\n",
    "        \"FEATURES\": FEATURES,\n",
    "        **{f\"test_{k}\": v for k, v in test_metrics.items()},\n",
    "        **{f\"val_{k}\": v for k, v in val_metrics.items()},\n",
    "        **model_parametres\n",
    "    }\n",
    "\n",
    "    # Convert dictionary to DataFrame\n",
    "    df = pd.DataFrame([data])\n",
    "    csv_file_name = f\"{MODEL}_results.csv\"\n",
    "\n",
    "    # Check if the CSV file already exists\n",
    "    if os.path.exists(csv_file_name):\n",
    "        # Load existing data\n",
    "        existing_df = pd.read_csv(csv_file_name)\n",
    "\n",
    "        # Concatenate new data with old data\n",
    "        updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "\n",
    "        # Drop duplicates\n",
    "        updated_df.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "        # Save the updated DataFrame to CSV\n",
    "        updated_df.to_csv(f\"../Outputs/{csv_file_name}\", index=False)\n",
    "    else:\n",
    "        # If the file does not exist, save the DataFrame as new file\n",
    "        df.to_csv(f\"../Outputs/{csv_file_name}\", index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main features to choose\n",
    "DATASET = 'cresci-2017'\n",
    "BOT_FOLDERS = [1, 1, 1] # Might be different between cresci_2015 and cresci_2017\n",
    "BOT_RATIO = [.35, .65] # Non-bot to Bot\n",
    "MERGED_DATASET = True # Merged dataset uses user info plus tweets \n",
    "TYPE_SELECTION = \"correlation\"\n",
    "TRAIN_RATE = .7\n",
    "TEST_RATE = .15\n",
    "VAL_RATE = .15\n",
    "MODEL = 'all'\n",
    "FEATURES = None # none equals to test all features, otherwise enter a number of features\n",
    "MODEL_P = None # Only use the template provided on top for modifying parametres for test\n",
    "GRID_SEARCH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "logistic_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:416: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n"
     ]
    }
   ],
   "source": [
    "# Import the data \n",
    "importer = ImportData()\n",
    "data = importer.read_and_sample_data(dataset = DATASET,\n",
    "                                     type_data_merged = MERGED_DATASET, \n",
    "                                     bot_ratio= BOT_RATIO, \n",
    "                                     bot_fldr_ratio= BOT_FOLDERS\n",
    "                                     )\n",
    "\n",
    "# Do a selection of features \n",
    "selection = FeatureSelection(data)\n",
    "list_features = selection.select_features(type_selection = TYPE_SELECTION)\n",
    "\n",
    "# Create the splits \n",
    "SPLIT_RATES = [TRAIN_RATE, TEST_RATE, VAL_RATE] \n",
    "splits = importer.split_dataset(data = data, \n",
    "                                proportions= SPLIT_RATES\n",
    "                                )\n",
    "\n",
    "# Test Model \n",
    "test_enviroment = ModelTester(splits, list_features)\n",
    "\n",
    "\n",
    "############################################## ALL MODELS PREDICTION ##################################################################\n",
    "if MODEL =='all':\n",
    "    # Multiple models results DF \n",
    "    results = {}\n",
    "\n",
    "    # Loop across all models\n",
    "    for model in test_enviroment.models.keys():\n",
    "        # Generate the predictions\n",
    "        predictions = {}\n",
    "\n",
    "        # check if model parametres need to be changed\n",
    "        if MODEL_P != None:\n",
    "            test_enviroment.change_model_parameters(model_name=model, \n",
    "                                                    new_params=models_parametres[model]\n",
    "                                                    )\n",
    "\n",
    "        # check if model parametres need to be optimized before prediction\n",
    "        if (MODEL_P == None) and (GRID_SEARCH == True):\n",
    "            test_enviroment.grid_search(model_name = model, \n",
    "                                        num_features = FEATURES)\n",
    "\n",
    "        # Get the current parametres for prediction\n",
    "        model_parametres = test_enviroment.models[model].get_params()\n",
    "        \n",
    "        # Create a prediction    \n",
    "        predictions = test_enviroment.predict_model(model_name = model, \n",
    "                                                    num_features= FEATURES\n",
    "                                                    )\n",
    "\n",
    "        # Evaluate the predictions for Test Dataset\n",
    "        val_evaluation = Evaluate(true_values=splits['y_val'], \n",
    "                           predicted_values= predictions['val_predictions'], \n",
    "                           predicted_probabilities= predictions['val_probabilities']\n",
    "                           )\n",
    "        val_metrics = val_evaluation.get_all_metrics()\n",
    "\n",
    "        # Evaluate the predictions for Test Dataset\n",
    "        test_evaluation = Evaluate(true_values=splits['y_test'], \n",
    "                           predicted_values= predictions['test_predictions'], \n",
    "                           predicted_probabilities= predictions['test_probabilities']\n",
    "                           )\n",
    "        test_metrics = test_evaluation.get_all_metrics()\n",
    "\n",
    "        print(model)\n",
    "\n",
    "        # Save the result\n",
    "        results[model] = save_results(\n",
    "            model_parametres=model_parametres,\n",
    "            test_metrics=test_metrics,  # Ensure the correct variable name is used\n",
    "            val_metrics=val_metrics,  # Ensure the correct variable name is used\n",
    "            DATASET=DATASET,\n",
    "            BOT_FOLDERS=BOT_FOLDERS,\n",
    "            BOT_RATIO=BOT_RATIO,\n",
    "            MERGED_DATASET=MERGED_DATASET,\n",
    "            TYPE_SELECTION=TYPE_SELECTION,\n",
    "            TRAIN_RATE=TRAIN_RATE,\n",
    "            TEST_RATE=TEST_RATE,\n",
    "            VAL_RATE=VAL_RATE,\n",
    "            MODEL=model,\n",
    "            FEATURES=FEATURES\n",
    "        )\n",
    "    \n",
    "######################################### SINGLE MODEL PREDICTION ########################################################################\n",
    "else:\n",
    "    # Generate the predictions\n",
    "    predictions = {}\n",
    "\n",
    "    # check if model parametres need to be changed\n",
    "    if MODEL_P != None:\n",
    "        test_enviroment.change_model_parameters(model_name=MODEL, \n",
    "                                                new_params=models_parametres[MODEL]\n",
    "                                                )\n",
    "\n",
    "    # check if model parametres need to be optimized before prediction\n",
    "    if (MODEL_P == None) and (GRID_SEARCH == True):\n",
    "        test_enviroment.grid_search(model_name = MODEL, \n",
    "                                    num_features = FEATURES)\n",
    "        \n",
    "    # Get the current parametres for prediction\n",
    "    model_parametres = test_enviroment.models[MODEL].get_params()\n",
    "\n",
    "    # Generate a prediction\n",
    "    predictions = test_enviroment.predict_model(model_name = MODEL, \n",
    "                                                num_features= FEATURES)\n",
    "\n",
    "    # Evaluate the predictions for Test Dataset\n",
    "    val_evaluation = Evaluate(true_values=splits['y_val'], \n",
    "                        predicted_values= predictions['val_predictions'], \n",
    "                        predicted_probabilities= predictions['val_probabilities']\n",
    "                        )\n",
    "    val_metrics = val_evaluation.get_all_metrics()\n",
    "\n",
    "    # Evaluate the predictions for Test Dataset\n",
    "    test_evaluation = Evaluate(true_values=splits['y_test'], \n",
    "                        predicted_values= predictions['test_predictions'], \n",
    "                        predicted_probabilities= predictions['test_probabilities']\n",
    "                        )\n",
    "    test_metrics = test_evaluation.get_all_metrics()\n",
    "    \n",
    "    # Save the result\n",
    "    df = save_results(\n",
    "        model_parametres=model_parametres,\n",
    "        test_metrics=test_metrics,  # Ensure the correct variable name is used\n",
    "        val_metrics=val_metrics,  # Ensure the correct variable name is used\n",
    "        DATASET=DATASET,\n",
    "        BOT_FOLDERS=BOT_FOLDERS,\n",
    "        BOT_RATIO=BOT_RATIO,\n",
    "        MERGED_DATASET=MERGED_DATASET,\n",
    "        TYPE_SELECTION=TYPE_SELECTION,\n",
    "        TRAIN_RATE=TRAIN_RATE,\n",
    "        TEST_RATE=TEST_RATE,\n",
    "        VAL_RATE=VAL_RATE,\n",
    "        MODEL=MODEL,\n",
    "        FEATURES=FEATURES\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATASET</th>\n",
       "      <th>BOT_FOLDERS</th>\n",
       "      <th>BOT_RATIO</th>\n",
       "      <th>MERGED_DATASET</th>\n",
       "      <th>TYPE_SELECTION</th>\n",
       "      <th>TRAIN_RATE</th>\n",
       "      <th>TEST_RATE</th>\n",
       "      <th>VAL_RATE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>test_Accuracy</th>\n",
       "      <th>test_TN Rate</th>\n",
       "      <th>test_FP Rate</th>\n",
       "      <th>test_FN Rate</th>\n",
       "      <th>test_TP Rate</th>\n",
       "      <th>test_Precision</th>\n",
       "      <th>test_Recall</th>\n",
       "      <th>test_F1 Score</th>\n",
       "      <th>test_MCC</th>\n",
       "      <th>test_AUC</th>\n",
       "      <th>val_Accuracy</th>\n",
       "      <th>val_TN Rate</th>\n",
       "      <th>val_FP Rate</th>\n",
       "      <th>val_FN Rate</th>\n",
       "      <th>val_TP Rate</th>\n",
       "      <th>val_Precision</th>\n",
       "      <th>val_Recall</th>\n",
       "      <th>val_F1 Score</th>\n",
       "      <th>val_MCC</th>\n",
       "      <th>val_AUC</th>\n",
       "      <th>C</th>\n",
       "      <th>break_ties</th>\n",
       "      <th>cache_size</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>coef0</th>\n",
       "      <th>decision_function_shape</th>\n",
       "      <th>degree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>probability</th>\n",
       "      <th>random_state</th>\n",
       "      <th>shrinking</th>\n",
       "      <th>tol</th>\n",
       "      <th>verbose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cresci-2017</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[0.35, 0.65]</td>\n",
       "      <td>True</td>\n",
       "      <td>correlation</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>svm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.967672</td>\n",
       "      <td>0.334052</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.633621</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.97351</td>\n",
       "      <td>0.975124</td>\n",
       "      <td>0.928981</td>\n",
       "      <td>0.992131</td>\n",
       "      <td>0.963441</td>\n",
       "      <td>0.335484</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.971714</td>\n",
       "      <td>0.920137</td>\n",
       "      <td>0.984297</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>ovr</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATASET BOT_FOLDERS     BOT_RATIO  MERGED_DATASET TYPE_SELECTION  \\\n",
       "0  cresci-2017   [1, 1, 1]  [0.35, 0.65]            True    correlation   \n",
       "\n",
       "   TRAIN_RATE  TEST_RATE  VAL_RATE MODEL FEATURES  test_Accuracy  \\\n",
       "0         0.7       0.15      0.15   svm     None       0.967672   \n",
       "\n",
       "   test_TN Rate  test_FP Rate  test_FN Rate  test_TP Rate  test_Precision  \\\n",
       "0      0.334052      0.015086      0.017241      0.633621        0.976744   \n",
       "\n",
       "   test_Recall  test_F1 Score  test_MCC  test_AUC  val_Accuracy  val_TN Rate  \\\n",
       "0      0.97351       0.975124  0.928981  0.992131      0.963441     0.335484   \n",
       "\n",
       "   val_FP Rate  val_FN Rate  val_TP Rate  val_Precision  val_Recall  \\\n",
       "0     0.015054     0.021505     0.627957       0.976589    0.966887   \n",
       "\n",
       "   val_F1 Score   val_MCC   val_AUC     C  break_ties  cache_size  \\\n",
       "0      0.971714  0.920137  0.984297  1000       False         200   \n",
       "\n",
       "  class_weight  coef0 decision_function_shape  degree  gamma kernel  max_iter  \\\n",
       "0     balanced    0.1                     ovr       2  scale   poly        -1   \n",
       "\n",
       "   probability random_state  shrinking    tol  verbose  \n",
       "0         True         None       True  0.001    False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) \n",
    "results['svm']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
