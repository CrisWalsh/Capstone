{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files \n",
    "tweets = pd.read_csv(\"../Data/cresci-2017.csv/datasets_full.csv/traditional_spambots_1.csv/traditional_spambots_1.csv/tweets.csv\", encoding='utf-8')\n",
    "users = pd.read_csv(\"../Data/cresci-2017.csv/datasets_full.csv/traditional_spambots_1.csv/traditional_spambots_1.csv/users.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I want to loop some values\n",
    "files_dict = {\n",
    "    'tweets': tweets,\n",
    "    'users': users\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe name: tweets\n",
      "            id                                               text  \\\n",
      "0  22642586115     CPPRI Recruitment 2010 at http://ping.fm/yp8zH   \n",
      "1  22642583483  National Games Secretariat Recruitment 2010  :...   \n",
      "2  22642524678     CIPET Recruitment Jobs at http://ping.fm/KnFCa   \n",
      "3  22642504361      DIAT Recruitment 2010 at http://ping.fm/huS9m   \n",
      "4  22642475789       BHEL Recruitment 2010 : http://ping.fm/PLWWA   \n",
      "\n",
      "                                              source  user_id  truncated  \\\n",
      "0  <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...  7248952        NaN   \n",
      "1  <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...  7248952        NaN   \n",
      "2  <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...  7248952        NaN   \n",
      "3  <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...  7248952        NaN   \n",
      "4  <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...  7248952        NaN   \n",
      "\n",
      "   in_reply_to_status_id  in_reply_to_user_id in_reply_to_screen_name  \\\n",
      "0                      0                    0                     NaN   \n",
      "1                      0                    0                     NaN   \n",
      "2                      0                    0                     NaN   \n",
      "3                      0                    0                     NaN   \n",
      "4                      0                    0                     NaN   \n",
      "\n",
      "   retweeted_status_id  geo  ...  favorited  retweeted  possibly_sensitive  \\\n",
      "0                    0  NaN  ...        NaN        NaN                 NaN   \n",
      "1                    0  NaN  ...        NaN        NaN                 NaN   \n",
      "2                    0  NaN  ...        NaN        NaN                 NaN   \n",
      "3                    0  NaN  ...        NaN        NaN                 NaN   \n",
      "4                    0  NaN  ...        NaN        NaN                 NaN   \n",
      "\n",
      "   num_hashtags  num_urls  num_mentions      created_at            timestamp  \\\n",
      "0             0         1             0  1283282654000L  2010-08-31 21:24:14   \n",
      "1             0         1             0  1283282651000L  2010-08-31 21:24:11   \n",
      "2             0         1             0  1283282592000L  2010-08-31 21:23:12   \n",
      "3             0         1             0  1283282571000L  2010-08-31 21:22:51   \n",
      "4             0         1             0  1283282543000L  2010-08-31 21:22:23   \n",
      "\n",
      "            crawled_at              updated  \n",
      "0  0000-00-00 00:00:00  2014-04-16 23:57:17  \n",
      "1  0000-00-00 00:00:00  2014-04-16 23:57:17  \n",
      "2  0000-00-00 00:00:00  2014-04-16 23:57:17  \n",
      "3  0000-00-00 00:00:00  2014-04-16 23:57:17  \n",
      "4  0000-00-00 00:00:00  2014-04-16 23:57:17  \n",
      "\n",
      "[5 rows x 25 columns] \n",
      "\n",
      "\n",
      "Dataframe name: users\n",
      "         id           name      screen_name  statuses_count  followers_count  \\\n",
      "0   7248952   Bhuvan Chand      tarunkjuyal            1259              837   \n",
      "1   7732472  Daniel Wagner     DanielWagner             770             3274   \n",
      "2   9524952    Andrew Lock       Andrewlock            1100            38849   \n",
      "3  10788822   Tim Thompson  yourinsaneworld            6497             5902   \n",
      "4  14596967        fxgenie          fxgenie            3203             2570   \n",
      "\n",
      "   friends_count  favourites_count  listed_count  \\\n",
      "0           1978              3200             9   \n",
      "1           3595                 8            22   \n",
      "2          34504                41          1014   \n",
      "3           5496                 0            82   \n",
      "4           2638                 0             5   \n",
      "\n",
      "                                     url  lang  ...  protected verified  \\\n",
      "0                 http://lifeofearth.org   NaN  ...        NaN      NaN   \n",
      "1  http://www.yourinternetbuddies.com/go   NaN  ...        NaN      NaN   \n",
      "2          http://www.helpmybusiness.com   NaN  ...        NaN      NaN   \n",
      "3       http://investing-information.com   NaN  ...        NaN      NaN   \n",
      "4              http://www.4xgenie.com/wp   NaN  ...        NaN      NaN   \n",
      "\n",
      "   notifications                                        description  \\\n",
      "0            NaN                                     Love Your Life   \n",
      "1            NaN  I am an internet marketing coach and mentor wh...   \n",
      "2            NaN  Marketing Geek & Presenter of 'Help! My Busine...   \n",
      "3            NaN  I am a member of a network of stock investing ...   \n",
      "4            NaN                                       forex trader   \n",
      "\n",
      "   contributors_enabled following      created_at            timestamp  \\\n",
      "0                   NaN       NaN  1183552203000L  2007-07-04 14:30:03   \n",
      "1                   NaN       NaN  1185440851000L  2007-07-26 11:07:31   \n",
      "2                   NaN       NaN  1192725360000L  2007-10-18 18:36:00   \n",
      "3                   NaN       NaN  1196614406000L  2007-12-02 17:53:26   \n",
      "4                   NaN       NaN  1209536534000L  2008-04-30 08:22:14   \n",
      "\n",
      "            crawled_at              updated  \n",
      "0  2010-11-07 11:10:52  2016-03-14 17:05:53  \n",
      "1  2010-11-07 11:10:52  2016-03-14 17:05:54  \n",
      "2  2010-11-07 11:10:52  2016-03-14 17:05:54  \n",
      "3  2010-11-07 11:10:52  2016-03-14 17:05:54  \n",
      "4  2010-11-07 11:10:52  2016-03-14 17:05:54  \n",
      "\n",
      "[5 rows x 40 columns] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial look of each one \n",
    "for name, df in files_dict.items():\n",
    "    print(f\"Dataframe name: {name}\")\n",
    "    print(df.head(),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe name: tweets\n",
      "(145094, 25) \n",
      "\n",
      "\n",
      "Dataframe name: users\n",
      "(1000, 40) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shapes\n",
    "for name, df in files_dict.items():\n",
    "    print(f\"Dataframe name: {name}\")\n",
    "    print(df.shape,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe name: tweets\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145094 entries, 0 to 145093\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   id                       145094 non-null  int64  \n",
      " 1   text                     145094 non-null  object \n",
      " 2   source                   145094 non-null  object \n",
      " 3   user_id                  145094 non-null  int64  \n",
      " 4   truncated                753 non-null     float64\n",
      " 5   in_reply_to_status_id    145094 non-null  int64  \n",
      " 6   in_reply_to_user_id      145094 non-null  int64  \n",
      " 7   in_reply_to_screen_name  11286 non-null   object \n",
      " 8   retweeted_status_id      145094 non-null  int64  \n",
      " 9   geo                      0 non-null       float64\n",
      " 10  place                    0 non-null       float64\n",
      " 11  contributors             0 non-null       float64\n",
      " 12  retweet_count            145094 non-null  int64  \n",
      " 13  reply_count              145094 non-null  int64  \n",
      " 14  favorite_count           145094 non-null  int64  \n",
      " 15  favorited                0 non-null       float64\n",
      " 16  retweeted                0 non-null       float64\n",
      " 17  possibly_sensitive       0 non-null       float64\n",
      " 18  num_hashtags             145094 non-null  int64  \n",
      " 19  num_urls                 145094 non-null  int64  \n",
      " 20  num_mentions             145094 non-null  int64  \n",
      " 21  created_at               145094 non-null  object \n",
      " 22  timestamp                145094 non-null  object \n",
      " 23  crawled_at               145094 non-null  object \n",
      " 24  updated                  145094 non-null  object \n",
      "dtypes: float64(7), int64(11), object(7)\n",
      "memory usage: 27.7+ MB\n",
      "None \n",
      "\n",
      "\n",
      "Dataframe name: users\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 40 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   id                                  1000 non-null   int64  \n",
      " 1   name                                1000 non-null   object \n",
      " 2   screen_name                         1000 non-null   object \n",
      " 3   statuses_count                      1000 non-null   int64  \n",
      " 4   followers_count                     1000 non-null   int64  \n",
      " 5   friends_count                       1000 non-null   int64  \n",
      " 6   favourites_count                    1000 non-null   int64  \n",
      " 7   listed_count                        1000 non-null   int64  \n",
      " 8   url                                 396 non-null    object \n",
      " 9   lang                                0 non-null      float64\n",
      " 10  time_zone                           0 non-null      float64\n",
      " 11  location                            243 non-null    object \n",
      " 12  default_profile                     0 non-null      float64\n",
      " 13  default_profile_image               0 non-null      float64\n",
      " 14  geo_enabled                         19 non-null     float64\n",
      " 15  profile_image_url                   1000 non-null   object \n",
      " 16  profile_banner_url                  0 non-null      float64\n",
      " 17  profile_use_background_image        0 non-null      float64\n",
      " 18  profile_background_image_url_https  0 non-null      float64\n",
      " 19  profile_text_color                  0 non-null      float64\n",
      " 20  profile_image_url_https             0 non-null      float64\n",
      " 21  profile_sidebar_border_color        0 non-null      float64\n",
      " 22  profile_background_tile             0 non-null      float64\n",
      " 23  profile_sidebar_fill_color          0 non-null      float64\n",
      " 24  profile_background_image_url        1000 non-null   object \n",
      " 25  profile_background_color            0 non-null      float64\n",
      " 26  profile_link_color                  0 non-null      float64\n",
      " 27  utc_offset                          0 non-null      float64\n",
      " 28  is_translator                       0 non-null      float64\n",
      " 29  follow_request_sent                 0 non-null      float64\n",
      " 30  protected                           0 non-null      float64\n",
      " 31  verified                            0 non-null      float64\n",
      " 32  notifications                       0 non-null      float64\n",
      " 33  description                         221 non-null    object \n",
      " 34  contributors_enabled                0 non-null      float64\n",
      " 35  following                           0 non-null      float64\n",
      " 36  created_at                          1000 non-null   object \n",
      " 37  timestamp                           1000 non-null   object \n",
      " 38  crawled_at                          1000 non-null   object \n",
      " 39  updated                             1000 non-null   object \n",
      "dtypes: float64(23), int64(6), object(11)\n",
      "memory usage: 312.6+ KB\n",
      "None \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Info\n",
    "for name, df in files_dict.items():\n",
    "    print(f\"Dataframe name: {name}\")\n",
    "    print(df.info(),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN id\n",
      "0    22642586115\n",
      "1    22642583483\n",
      "2    22642524678\n",
      "3    22642504361\n",
      "4    22642475789\n",
      "Name: id, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN text\n",
      "0       CPPRI Recruitment 2010 at http://ping.fm/yp8zH\n",
      "1    National Games Secretariat Recruitment 2010  :...\n",
      "2       CIPET Recruitment Jobs at http://ping.fm/KnFCa\n",
      "3        DIAT Recruitment 2010 at http://ping.fm/huS9m\n",
      "4         BHEL Recruitment 2010 : http://ping.fm/PLWWA\n",
      "Name: text, dtype: object \n",
      "\n",
      "\n",
      "COLUMN source\n",
      "0    <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...\n",
      "1    <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...\n",
      "2    <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...\n",
      "3    <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...\n",
      "4    <a href=\"http://www.ping.fm/\" rel=\"nofollow\">P...\n",
      "Name: source, dtype: object \n",
      "\n",
      "\n",
      "COLUMN user_id\n",
      "0    7248952\n",
      "1    7248952\n",
      "2    7248952\n",
      "3    7248952\n",
      "4    7248952\n",
      "Name: user_id, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN truncated\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: truncated, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN in_reply_to_status_id\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: in_reply_to_status_id, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN in_reply_to_user_id\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: in_reply_to_user_id, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN in_reply_to_screen_name\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "Name: in_reply_to_screen_name, dtype: object \n",
      "\n",
      "\n",
      "COLUMN retweeted_status_id\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: retweeted_status_id, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN geo\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: geo, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN place\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: place, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN contributors\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: contributors, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN retweet_count\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: retweet_count, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN reply_count\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: reply_count, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN favorite_count\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: favorite_count, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN favorited\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: favorited, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN retweeted\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: retweeted, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN possibly_sensitive\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: possibly_sensitive, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN num_hashtags\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: num_hashtags, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN num_urls\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: num_urls, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN num_mentions\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: num_mentions, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN created_at\n",
      "0    1283282654000L\n",
      "1    1283282651000L\n",
      "2    1283282592000L\n",
      "3    1283282571000L\n",
      "4    1283282543000L\n",
      "Name: created_at, dtype: object \n",
      "\n",
      "\n",
      "COLUMN timestamp\n",
      "0    2010-08-31 21:24:14\n",
      "1    2010-08-31 21:24:11\n",
      "2    2010-08-31 21:23:12\n",
      "3    2010-08-31 21:22:51\n",
      "4    2010-08-31 21:22:23\n",
      "Name: timestamp, dtype: object \n",
      "\n",
      "\n",
      "COLUMN crawled_at\n",
      "0    0000-00-00 00:00:00\n",
      "1    0000-00-00 00:00:00\n",
      "2    0000-00-00 00:00:00\n",
      "3    0000-00-00 00:00:00\n",
      "4    0000-00-00 00:00:00\n",
      "Name: crawled_at, dtype: object \n",
      "\n",
      "\n",
      "COLUMN updated\n",
      "0    2014-04-16 23:57:17\n",
      "1    2014-04-16 23:57:17\n",
      "2    2014-04-16 23:57:17\n",
      "3    2014-04-16 23:57:17\n",
      "4    2014-04-16 23:57:17\n",
      "Name: updated, dtype: object \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understand each feature\n",
    "for column in tweets.columns:\n",
    "    print(f\"COLUMN {column}\")\n",
    "    print(tweets[column].head(), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN id\n",
      "0     7248952\n",
      "1     7732472\n",
      "2     9524952\n",
      "3    10788822\n",
      "4    14596967\n",
      "Name: id, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN name\n",
      "0     Bhuvan Chand\n",
      "1    Daniel Wagner\n",
      "2      Andrew Lock\n",
      "3     Tim Thompson\n",
      "4          fxgenie\n",
      "Name: name, dtype: object \n",
      "\n",
      "\n",
      "COLUMN screen_name\n",
      "0        tarunkjuyal\n",
      "1       DanielWagner\n",
      "2         Andrewlock\n",
      "3    yourinsaneworld\n",
      "4            fxgenie\n",
      "Name: screen_name, dtype: object \n",
      "\n",
      "\n",
      "COLUMN statuses_count\n",
      "0    1259\n",
      "1     770\n",
      "2    1100\n",
      "3    6497\n",
      "4    3203\n",
      "Name: statuses_count, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN followers_count\n",
      "0      837\n",
      "1     3274\n",
      "2    38849\n",
      "3     5902\n",
      "4     2570\n",
      "Name: followers_count, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN friends_count\n",
      "0     1978\n",
      "1     3595\n",
      "2    34504\n",
      "3     5496\n",
      "4     2638\n",
      "Name: friends_count, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN favourites_count\n",
      "0    3200\n",
      "1       8\n",
      "2      41\n",
      "3       0\n",
      "4       0\n",
      "Name: favourites_count, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN listed_count\n",
      "0       9\n",
      "1      22\n",
      "2    1014\n",
      "3      82\n",
      "4       5\n",
      "Name: listed_count, dtype: int64 \n",
      "\n",
      "\n",
      "COLUMN url\n",
      "0                   http://lifeofearth.org\n",
      "1    http://www.yourinternetbuddies.com/go\n",
      "2            http://www.helpmybusiness.com\n",
      "3         http://investing-information.com\n",
      "4                http://www.4xgenie.com/wp\n",
      "Name: url, dtype: object \n",
      "\n",
      "\n",
      "COLUMN lang\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: lang, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN time_zone\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: time_zone, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN location\n",
      "0        Berekely\n",
      "1              UK\n",
      "2    Planet Earth\n",
      "3     Houston, TX\n",
      "4             usa\n",
      "Name: location, dtype: object \n",
      "\n",
      "\n",
      "COLUMN default_profile\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: default_profile, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN default_profile_image\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: default_profile_image, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN geo_enabled\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: geo_enabled, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_image_url\n",
      "0    http://a1.twimg.com/profile_images/53905961/st...\n",
      "1    http://a3.twimg.com/profile_images/719249843/d...\n",
      "2    http://a3.twimg.com/profile_images/516987291/b...\n",
      "3    http://a3.twimg.com/profile_images/200984855/t...\n",
      "4    http://a2.twimg.com/profile_images/53530606/sh...\n",
      "Name: profile_image_url, dtype: object \n",
      "\n",
      "\n",
      "COLUMN profile_banner_url\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_banner_url, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_use_background_image\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_use_background_image, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_background_image_url_https\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_background_image_url_https, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_text_color\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_text_color, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_image_url_https\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_image_url_https, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_sidebar_border_color\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_sidebar_border_color, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_background_tile\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_background_tile, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_sidebar_fill_color\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_sidebar_fill_color, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_background_image_url\n",
      "0    http://s.twimg.com/a/1288374569/images/themes/...\n",
      "1    http://a3.twimg.com/profile_background_images/...\n",
      "2    http://s.twimg.com/a/1288305442/images/themes/...\n",
      "3    http://s.twimg.com/a/1288039940/images/themes/...\n",
      "4    http://a1.twimg.com/profile_background_images/...\n",
      "Name: profile_background_image_url, dtype: object \n",
      "\n",
      "\n",
      "COLUMN profile_background_color\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_background_color, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN profile_link_color\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: profile_link_color, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN utc_offset\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: utc_offset, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN is_translator\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: is_translator, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN follow_request_sent\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: follow_request_sent, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN protected\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: protected, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN verified\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: verified, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN notifications\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: notifications, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN description\n",
      "0                                       Love Your Life\n",
      "1    I am an internet marketing coach and mentor wh...\n",
      "2    Marketing Geek & Presenter of 'Help! My Busine...\n",
      "3    I am a member of a network of stock investing ...\n",
      "4                                         forex trader\n",
      "Name: description, dtype: object \n",
      "\n",
      "\n",
      "COLUMN contributors_enabled\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: contributors_enabled, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN following\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: following, dtype: float64 \n",
      "\n",
      "\n",
      "COLUMN created_at\n",
      "0    1183552203000L\n",
      "1    1185440851000L\n",
      "2    1192725360000L\n",
      "3    1196614406000L\n",
      "4    1209536534000L\n",
      "Name: created_at, dtype: object \n",
      "\n",
      "\n",
      "COLUMN timestamp\n",
      "0    2007-07-04 14:30:03\n",
      "1    2007-07-26 11:07:31\n",
      "2    2007-10-18 18:36:00\n",
      "3    2007-12-02 17:53:26\n",
      "4    2008-04-30 08:22:14\n",
      "Name: timestamp, dtype: object \n",
      "\n",
      "\n",
      "COLUMN crawled_at\n",
      "0    2010-11-07 11:10:52\n",
      "1    2010-11-07 11:10:52\n",
      "2    2010-11-07 11:10:52\n",
      "3    2010-11-07 11:10:52\n",
      "4    2010-11-07 11:10:52\n",
      "Name: crawled_at, dtype: object \n",
      "\n",
      "\n",
      "COLUMN updated\n",
      "0    2016-03-14 17:05:53\n",
      "1    2016-03-14 17:05:54\n",
      "2    2016-03-14 17:05:54\n",
      "3    2016-03-14 17:05:54\n",
      "4    2016-03-14 17:05:54\n",
      "Name: updated, dtype: object \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understand each feature\n",
    "for column in users.columns:\n",
    "    print(f\"COLUMN {column}\")\n",
    "    print(users[column].head(), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features to Keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_features = [\"user_id\", \"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"]\n",
    "Users_features = [\"id\", \"statuses_count\", \"followers_count\", \"friends_count\", \"favourites_count\", \"listed_count\", \"created_at\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = tweets[Tweets_features]\n",
    "users = users[Users_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1183552203000L\n",
       "1      1185440851000L\n",
       "2      1192725360000L\n",
       "3      1196614406000L\n",
       "4      1209536534000L\n",
       "            ...      \n",
       "995    1267038541000L\n",
       "996    1267067845000L\n",
       "997    1267077720000L\n",
       "998    1267078126000L\n",
       "999    1268008058000L\n",
       "Name: created_at, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Unknown string format: 1183552203000L present at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:605\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:318\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DEFAULTPARSER\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:643\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown string format: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, timestr)\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mParserError\u001b[0m: Unknown string format: 1183552203000L",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:616\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid string coercion to datetime for \"1183552203000L\" at position 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m users[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43musers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1068\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1068\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[0;32m    437\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 438\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2175\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2186\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;66;03m# Exception is raised when a part of date is greater than 32 bit signed int\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:683\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:829\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:819\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:318\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser(parserinfo)\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DEFAULTPARSER\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jmanu\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:643\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m res, skipped_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown string format: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, timestr)\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mString does not contain a date: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, timestr)\n",
      "\u001b[1;31mParserError\u001b[0m: Unknown string format: 1183552203000L present at position 0"
     ]
    }
   ],
   "source": [
    "users['created_at'] = pd.to_datetime(users['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_37636\\1915932557.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets[col] = tweets[col].fillna(0)\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_37636\\1915932557.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users[col] = users[col].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values for all numeric columns in tweets DataFrame\n",
    "for col in tweets.columns:\n",
    "    if pd.api.types.is_numeric_dtype(tweets[col]):\n",
    "        tweets[col] = tweets[col].fillna(0)\n",
    "\n",
    "# Fill missing values for all numeric columns in users DataFrame\n",
    "for col in users.columns:\n",
    "    if pd.api.types.is_numeric_dtype(users[col]):\n",
    "        users[col] = users[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engeniering in Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_37636\\3474127401.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users['account_age_years'] = 2015 - users['created_at'].dt.year\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_37636\\3474127401.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users['followers_to_friends_ratio'] = users['followers_count'] / users['friends_count']\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_37636\\3474127401.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users['followers_to_friends_ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_37636\\3474127401.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users['followers_to_friends_ratio'] = users['followers_to_friends_ratio'].fillna(0)  # Handle division by zero\n"
     ]
    }
   ],
   "source": [
    "users['account_age_years'] = 2015 - users['created_at'].dt.year\n",
    "users['followers_to_friends_ratio'] = users['followers_count'] / users['friends_count']\n",
    "users['followers_to_friends_ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "users['followers_to_friends_ratio'] = users['followers_to_friends_ratio'].fillna(0)  # Handle division by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.drop([\"created_at\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_37636\\2251798934.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets[\"num_tweets\"] = 1\n"
     ]
    }
   ],
   "source": [
    "tweets[\"num_tweets\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.groupby(['user_id']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"retweet_ratio\"] = tweets[\"retweet_count\"]/tweets[\"num_tweets\"]\n",
    "tweets[\"reply_ration\"] = tweets[\"reply_count\"]/tweets[\"num_tweets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "users.iloc[:,1:] = scaler.fit_transform(users.iloc[:,1:])\n",
    "tweets.iloc[:,1:] = scaler.fit_transform(tweets.iloc[:,1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(tweets, users, left_on='user_id', right_on='id', how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new folder path\n",
    "new_folder_path = './E13.csv/clean'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(new_folder_path):\n",
    "    os.makedirs(new_folder_path)\n",
    "\n",
    "merged_df.to_csv(f'{new_folder_path}/clean_merged.csv', index=False, encoding='utf-8')\n",
    "users.to_csv(f'{new_folder_path}/clean_users.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop Across Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genuine_accounts.csv',\n",
       " 'social_spambots_1.csv',\n",
       " 'social_spambots_2.csv',\n",
       " 'social_spambots_3.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where your main folders (genuine_accounts.csv, etc.) are located\n",
    "base_directory = \"../Data/cresci-2017.csv/datasets_full.csv/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing datasets in genuine_accounts.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_34416\\1831354226.py:21: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(tweets_path, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets: 2839362 rows, Users: 3474 rows\n",
      "******FILES SAVED********\n",
      "\n",
      "\n",
      "Processing datasets in social_spambots_1.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_34416\\1831354226.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(tweets_path, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets: 1610034 rows, Users: 991 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_34416\\1831354226.py:67: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tweets.iloc[:,1:] = scaler.fit_transform(tweets.iloc[:,1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******FILES SAVED********\n",
      "\n",
      "\n",
      "Processing datasets in social_spambots_2.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_34416\\1831354226.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(tweets_path, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets: 428542 rows, Users: 3457 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_34416\\1831354226.py:67: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tweets.iloc[:,1:] = scaler.fit_transform(tweets.iloc[:,1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******FILES SAVED********\n",
      "\n",
      "\n",
      "Processing datasets in social_spambots_3.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_34416\\1831354226.py:21: DtypeWarning: Columns (7,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(tweets_path, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets: 1418557 rows, Users: 464 rows\n",
      "******FILES SAVED********\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmanu\\AppData\\Local\\Temp\\ipykernel_34416\\1831354226.py:67: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  tweets.iloc[:,1:] = scaler.fit_transform(tweets.iloc[:,1:])\n"
     ]
    }
   ],
   "source": [
    "# Base directory where your main folders (genuine_accounts.csv, etc.) are located\n",
    "base_directory = \"../Data/cresci-2017.csv/datasets_full.csv/\"\n",
    "\n",
    "# List all main folders in the base directory\n",
    "main_folders = [f for f in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, f))]\n",
    "\n",
    "# Loop through each main folder\n",
    "for main_folder in main_folders:\n",
    "\n",
    "    # Construct the path to the nested folder, assuming the repeated structure\n",
    "    nested_folder_path = os.path.join(base_directory, main_folder, main_folder)\n",
    "    \n",
    "    # Construct the full paths to tweets.csv and users.csv within the nested folder\n",
    "    tweets_path = os.path.join(nested_folder_path, \"tweets.csv\")\n",
    "    users_path = os.path.join(nested_folder_path, \"users.csv\")\n",
    "\n",
    "    # Now you can process these datasets as needed\n",
    "    print(f\"Processing datasets in {main_folder}...\")\n",
    "    \n",
    "    # Load the datasets\n",
    "    tweets = pd.read_csv(tweets_path, encoding='utf-8')\n",
    "    users = pd.read_csv(users_path, encoding='utf-8')\n",
    "\n",
    "    # Example processing: Just printing out the number of rows in each file\n",
    "    print(f\"Tweets: {tweets.shape[0]} rows, Users: {users.shape[0]} rows\")\n",
    "\n",
    "    # Reduce the features \n",
    "    Tweets_features = [\"user_id\", \"retweet_count\", \"reply_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"]\n",
    "    Users_features = [\"id\", \"statuses_count\", \"followers_count\", \"friends_count\", \"favourites_count\", \"listed_count\", \"created_at\"]\n",
    "    tweets = tweets[Tweets_features]\n",
    "    users = users[Users_features]\n",
    "\n",
    "    # Convert Data Type\n",
    "    users['created_at'] = pd.to_datetime(users['created_at'])\n",
    "\n",
    "    # Missing Values\n",
    "    # Fill missing values for all numeric columns in tweets DataFrame\n",
    "    for col in tweets.columns:\n",
    "        if pd.api.types.is_numeric_dtype(tweets[col]):\n",
    "            tweets[col] = tweets[col].fillna(0)\n",
    "\n",
    "    # Fill missing values for all numeric columns in users DataFrame\n",
    "    for col in users.columns:\n",
    "        if pd.api.types.is_numeric_dtype(users[col]):\n",
    "            users[col] = users[col].fillna(0)\n",
    "\n",
    "    # User Feature Eng\n",
    "    users['account_age_years'] = 2017 - users['created_at'].dt.year\n",
    "    users['followers_to_friends_ratio'] = users['followers_count'] / users['friends_count']\n",
    "    users['followers_to_friends_ratio'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    users['followers_to_friends_ratio'] = users['followers_to_friends_ratio'].fillna(0)\n",
    "\n",
    "    # Drop Date\n",
    "    users = users.drop([\"created_at\"], axis=1)\n",
    "\n",
    "    # Aggregate Tweet\n",
    "    tweets[\"num_tweets\"] = 1\n",
    "    tweets = tweets.groupby(['user_id']).sum().reset_index()\n",
    "\n",
    "    # Feature Eng Tweets\n",
    "    tweets[\"retweet_ratio\"] = tweets[\"retweet_count\"]/tweets[\"num_tweets\"]\n",
    "    tweets[\"reply_ration\"] = tweets[\"reply_count\"]/tweets[\"num_tweets\"]\n",
    "\n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler()\n",
    "    users.iloc[:,1:] = scaler.fit_transform(users.iloc[:,1:])\n",
    "    tweets.iloc[:,1:] = scaler.fit_transform(tweets.iloc[:,1:])\n",
    "\n",
    "    # Merge\n",
    "    merged_df = pd.merge(tweets, users, left_on='user_id', right_on='id', how='inner')\n",
    "\n",
    "    # Add bot feature\n",
    "    if main_folder == 'genuine_accounts.csv':\n",
    "        merged_df[\"bot\"] = 0\n",
    "        users[\"bot\"] = 0\n",
    "    else:\n",
    "        merged_df[\"bot\"] = 1\n",
    "        users[\"bot\"] = 1\n",
    "\n",
    "    # Define the new folder path\n",
    "    new_folder_path = f'./{main_folder}/{main_folder}/clean'\n",
    "\n",
    "    # Create the folder if it does not exist\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "\n",
    "    merged_df.to_csv(f'{new_folder_path}/clean_merged.csv', index=False, encoding='utf-8')\n",
    "    users.to_csv(f'{new_folder_path}/clean_users.csv', index=False, encoding='utf-8')\n",
    "    print(\"******FILES SAVED********\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E13.csv', 'FSF.csv', 'INT.csv', 'TFP.csv', 'TWT.csv']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if folder == 'E13.csv' or folder == 'TFP.csv':\n",
    "    merged_df[\"bot\"] = 0\n",
    "    users[\"bot\"] = 0\n",
    "else:\n",
    "    merged_df[\"bot\"] = 1\n",
    "    users[\"bot\"] = 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
